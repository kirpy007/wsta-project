{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Loading Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pprint\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preprocessing and tokenizing function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return [word for word in word_tokenize(stem_text(strip_punctuation(text.lower().replace(\"\\n\", \"\"))))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Initializing global variables </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "files = glob.glob('/home/rohan/Documents/Homework/WSTA/wiki-pages-text/*.txt')\n",
    "files = [file for file in files if file != '/home/rohan/Documents/Homework/WSTA/wiki-pages-text/to_test.txt']\n",
    "files = ['/home/rohan/Documents/Homework/WSTA/wiki-pages-text/wiki-047.txt']\n",
    "doc_dict = {}\n",
    "file_dict = {}\n",
    "df = pd.DataFrame()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "punc_table = str.maketrans({key: None for key in string.punctuation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reading files into a dictionary </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rohan/Documents/Homework/WSTA/wiki-pages-text/wiki-047.txt\n",
      "Time taken:  0.28923964500427246\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for file in enumerate(files):\n",
    "    with open(file, encoding = 'utf-8') as f:\n",
    "        print(file)\n",
    "        for line in f:\n",
    "            try:\n",
    "                #print(line)\n",
    "                line = line.split(maxsplit=2)\n",
    "                #print(line)\n",
    "                key = line[0]\n",
    "                value = line[2]\n",
    "                if key in file_dict.keys():\n",
    "                    file_dict[key] = file_dict[key] + value\n",
    "                else:\n",
    "                    file_dict[key] = value\n",
    "                    #print(value)\n",
    "            except Exception as e:\n",
    "                print(\"ERROR\",e, line)\n",
    "        for key, values in file_dict.items():\n",
    "            doc_dict[key] = values\n",
    "        #print(file_dict)\n",
    "print(\"Time taken: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading into Dataframe </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(doc_dict.items(),columns=['doc_id','doc'])\n",
    "del doc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pickle dataframe </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl_name = file.split('/')[-1].split(\".\")[0]\n",
    "df.to_pickle(\"wiki_47\" + \".pickle\")\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load pickled dataframe </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5396106, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('all_wiki.pickle')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Israeli_legislative_election,_2013</td>\n",
       "      <td>Early elections for the nineteenth Knesset wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>International_Mathematics_and_Design_Association</td>\n",
       "      <td>The International Mathematics &amp; Design Associa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interstellar_Low_Ways</td>\n",
       "      <td>Interstellar Low Ways is an album recorded by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jack_Daniel's_Racing</td>\n",
       "      <td>Jack Daniel 's Racing may refer to either of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inba_Station</td>\n",
       "      <td>is a railway station operated by Meitetsu 's S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             doc_id  \\\n",
       "0                Israeli_legislative_election,_2013   \n",
       "1  International_Mathematics_and_Design_Association   \n",
       "2                             Interstellar_Low_Ways   \n",
       "3                              Jack_Daniel's_Racing   \n",
       "4                                      Inba_Station   \n",
       "\n",
       "                                                 doc  \n",
       "0  Early elections for the nineteenth Knesset wer...  \n",
       "1  The International Mathematics & Design Associa...  \n",
       "2  Interstellar Low Ways is an album recorded by ...  \n",
       "3  Jack Daniel 's Racing may refer to either of t...  \n",
       "4  is a railway station operated by Meitetsu 's S...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1349026, 2)\n"
     ]
    }
   ],
   "source": [
    "df_4 = df.iloc[lambda x: x.index % 4 == 3]\n",
    "print(df_4.shape)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Print dataframe and preprocess document</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1349026\n",
      "Time taken: 1015.4041588306427\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_4['doc'] = df_4['doc'].apply(preprocess)\n",
    "print(\"Number of documents:\", len(df_4))\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Pickling preprocessed docs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Loading pickled processed dataframes </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_1 = pd.read_pickle('all_wiki_processed_1.pickle')\n",
    "#df_2 = pd.read_pickle('all_wiki_processed_2.pickle')\n",
    "#df_3 = pd.read_pickle('all_wiki_processed_3.pickle')\n",
    "df_4 = pd.read_pickle('all_wiki_processed_4.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Create Gensim dictionary </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1674392 unique tokens: ['australian', 'brett', 'championshipperkin', 'championshiprichard', 'childress']...)\n",
      "Time taken: 108.66674947738647\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dictionary = gensim.corpora.Dictionary(df_4['doc'].tolist())\n",
    "print(dictionary)\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save_as_text('dictionary_4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Creating BOW represention of documents </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 3), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 3), (26, 4), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 2), (35, 1), (36, 1), (37, 2), (38, 1), (39, 4), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 2), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 2), (60, 1), (61, 1), (62, 1), (63, 1), (64, 2), (65, 1), (66, 14), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 3), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1)], [(6, 1), (12, 1), (13, 1), (23, 1), (58, 1), (59, 1), (66, 3), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1)], [(6, 1), (11, 6), (12, 1), (13, 1), (20, 1), (32, 4), (35, 1), (39, 6), (58, 5), (59, 3), (62, 2), (66, 16), (72, 1), (76, 1), (98, 3), (99, 1), (104, 4), (114, 1), (116, 2), (117, 1), (118, 1), (119, 1), (120, 1), (121, 3), (122, 1), (123, 1), (124, 1), (125, 4), (126, 1), (127, 1), (128, 1), (129, 4), (130, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 1), (143, 1), (144, 2), (145, 1), (146, 1), (147, 1), (148, 1), (149, 3), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 2), (161, 1), (162, 1), (163, 1), (164, 2), (165, 1), (166, 1), (167, 1), (168, 1), (169, 1), (170, 1), (171, 4), (172, 2), (173, 1), (174, 1), (175, 1), (176, 1), (177, 2), (178, 3), (179, 1), (180, 1), (181, 1), (182, 2), (183, 2), (184, 1), (185, 1), (186, 1), (187, 1), (188, 1), (189, 1), (190, 4), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 1), (199, 1), (200, 2), (201, 1), (202, 1), (203, 2), (204, 1), (205, 2), (206, 1), (207, 3), (208, 1), (209, 1), (210, 1), (211, 1), (212, 3), (213, 1), (214, 2), (215, 1), (216, 1), (217, 1), (218, 2), (219, 1)], [(58, 1), (62, 1), (66, 1), (71, 1), (97, 2), (185, 1), (220, 1), (221, 1), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 5), (236, 1), (237, 1), (238, 1), (239, 2), (240, 1), (241, 2)], [(6, 1), (13, 1), (39, 1), (58, 1), (62, 1), (66, 1), (93, 1), (98, 2), (99, 1), (129, 1), (159, 2), (242, 1), (243, 1), (244, 1), (245, 1), (246, 1), (247, 2), (248, 1), (249, 1), (250, 1), (251, 1), (252, 1), (253, 1), (254, 1), (255, 1), (256, 2), (257, 1)]]\n",
      "Time taken: 2.1273293495178223\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['doc_processed'].tolist()]\n",
    "print(corpus[:5])\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Creating tf-idf model from this corpus </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.tfidfmodel.TfidfModel'>\n",
      "2893130\n",
      "Time taken: 0.6749780178070068\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "print(type(tf_idf))\n",
    "s = 0\n",
    "for i in corpus:\n",
    "    s += len(i)\n",
    "print(s)\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Creating Similarity index </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  19.05685067176819\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sims = gensim.similarities.Similarity('/home/rohan/Documents/Homework/WSTA/work_dir',tf_idf[corpus], num_features=len(dictionary))\n",
    "print(\"Time taken: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Getting query and showing documents related to the query </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Enter statement: \")\n",
    "start = time.time()\n",
    "query_doc = preprocess(query)\n",
    "query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "print(query_doc_tf_idf)\n",
    "sim_list = sims[query_doc_tf_idf]\n",
    "df['similarity_score'] = sim_list\n",
    "print(type(sim_list), len(sim_list))\n",
    "print(df.nlargest(5, ['similarity_score']))\n",
    "#print(\"Position of most relevant doc: \", max_index)\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
